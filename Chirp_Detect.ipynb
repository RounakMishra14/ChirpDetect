{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths To The Dataset\n",
    "DATA_DIR = 'augmented_data' \n",
    "BIRD_CLASSES = ['collared_dove', 'indian_mayna', 'kingfisher', 'nightangale', 'owl', 'sparrow', 'noise', 'unknown']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(filename):\n",
    "    # Load the audio file using librosa\n",
    "    wav, sample_rate = librosa.load(filename, sr=16000, mono=True)\n",
    "    \n",
    "    # Convert the wav to a mono channel if itâ€™s not already\n",
    "    if wav.ndim > 1:\n",
    "        wav = librosa.to_mono(wav)\n",
    "        \n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    # Load the audio file and convert to a mono channel\n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    \n",
    "    # Compute the STFT of the audio signal\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
    "    \n",
    "    # Take the absolute value of the STFT to get the magnitude spectrogram\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    \n",
    "    # Add the channel dimension to make the spectrogram 3D (height, width, channels)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=-1)  # Shape becomes (time, frequency, 1)\n",
    "    \n",
    "    # Ensure fixed size by padding or truncating (150 time steps, 257 frequency bins, 1 channel)\n",
    "    desired_shape = (150, 257, 1)\n",
    "    spectrogram = tf.image.resize_with_crop_or_pad(spectrogram, desired_shape[0], desired_shape[1])\n",
    "    \n",
    "    return spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the audio file to get the spectrogram\n",
    "spect = preprocess(os.path.join('augmented_data', 'collared_dove', 'collared_dove_sample1_sample10_aug3.wav'))\n",
    "\n",
    "# Transpose the spectrogram for better visualization\n",
    "spect = tf.transpose(spect, perm=[1, 0, 2])  # Transposing time and frequency for a better display\n",
    "\n",
    "# Remove the channel dimension for plotting\n",
    "spect = tf.squeeze(spect, axis=-1)\n",
    "\n",
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.imshow(spect, aspect='auto', origin='lower', cmap='inferno')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio files and labels into a TensorFlow dataset\n",
    "def load_dataset(data_dir, classes):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, bird_class in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, bird_class)\n",
    "        for file in os.listdir(class_dir):\n",
    "            if file.endswith('.wav'):  # Ensure only audio files are processed\n",
    "                file_path = os.path.join(class_dir, file)\n",
    "                \n",
    "                # Preprocess the audio file to get the spectrogram\n",
    "                spectrogram = preprocess(file_path)\n",
    "                \n",
    "                # Append the preprocessed data and corresponding label\n",
    "                data.append(spectrogram)\n",
    "                labels.append(label)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_dataset(DATA_DIR, BIRD_CLASSES)\n",
    "\n",
    "# Shuffle and split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Convert to TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(16).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2], 1)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    GlobalAveragePooling2D(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Reduce overfitting\n",
    "    \n",
    "    Dense(len(BIRD_CLASSES), activation='softmax')  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# View the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_dataset, epochs=50, validation_data=test_dataset)\n",
    "\n",
    "# Plot training and validation accuracy/loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('bird_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
